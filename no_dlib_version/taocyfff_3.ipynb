{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "taocyfff_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Create CNN"
      ],
      "metadata": {
        "id": "lORF4L3M5Mte"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GjC2h8TnyoEN"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import (\n",
        "    Conv2D, MaxPooling2D, Flatten,\n",
        "    Dense, Dropout, Input\n",
        ")\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from skimage.io import imshow\n",
        "from os.path import join\n",
        "import glob\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.color import rgb2gray\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to google\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Get the preprocessed train and test data\n",
        "training_data = pd.read_csv('/content/gdrive/MyDrive/training.csv')\n",
        "test_data = pd.read_csv('/content/gdrive/MyDrive/test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dPe-M5ey1Zq",
        "outputId": "e06427df-ce9c-4bf0-a901-8c3a91443218"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture\n",
        "def create_model():\n",
        "    '''\n",
        "    Define a CNN where input to the model must be a 96 by 96 pixel, greyscale, image\n",
        "    -------\n",
        "    Returns:\n",
        "    -------\n",
        "    model: A fully-connected output layer with 30 facial keypoints\n",
        "    '''\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv2D(32, (5,5), activation='relu', input_shape=(96, 96, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    \n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(30))\n",
        "    return model"
      ],
      "metadata": {
        "id": "LpDfmgpfy1eo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "def compile_model(model, optimizer, loss, metrics):\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "metadata": {
        "id": "s_WJmc8Hy1if"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "def train_model(model, X_train, y_train):\n",
        "    return model.fit(X_train, y_train, epochs=100, batch_size=200, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "id": "Umxo4TJsy1nQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights for a previously trained model\n",
        "def load_trained_model(model):\n",
        "    model.load_weights('weights/checkpoint-300.hdf5')"
      ],
      "metadata": {
        "id": "TQV7feE1y1sX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "def test_model(model):    \n",
        "    data_path = join('','*g')\n",
        "    files = glob.glob(data_path)\n",
        "    # Test model performance on a screenshot for the webcam\n",
        "    for i,f1 in enumerate(files):    \n",
        "        if f1 == 'Capture.PNG':\n",
        "            img = imread(f1)\n",
        "            # Convert RGB image to grayscale\n",
        "            img = rgb2gray(img)\n",
        "            # Resize to an array of size 96x96\n",
        "            test_img = resize(img, (96,96))\n",
        "      test_img = np.array(test_img)\n",
        "      # Model takes input of shape = [batch_size, height, width, no. of channels]\n",
        "      test_img_input = np.reshape(test_img, (1,96,96,1))\n",
        "      # shape = [batch_size, values]\n",
        "      prediction = model.predict(test_img_input)\n",
        "      visualize_points(test_img, prediction[0])\n",
        "\n",
        "\n",
        "      # Test on first 10 samples of the test set\n",
        "      for i in range(len(imgs_test)):\n",
        "            # Model takes input of shape = [batch_size, height, width, no. of channels]\n",
        "            test_img_input = np.reshape(imgs_test[i], (1,96,96,1))\n",
        "            # shape = [batch_size, values]\n",
        "            visualize_points(imgs_test[i], prediction[0])\n",
        "            if i == 10:\n",
        "                break      \n",
        "\n",
        "\n",
        "\n",
        "                      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "K9cm0iwEy1vq",
        "outputId": "80640422-a4c2-4aee-e0a3-bda086150104"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-dd6135f3fdde>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    test_img = np.array(test_img)\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = get_model()\n",
        "compile_model(model)\n",
        "#train_model(model)\n",
        "load_trained_model(model)\n",
        "test_model(model)"
      ],
      "metadata": {
        "id": "duIzungXy10Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data"
      ],
      "metadata": {
        "id": "R_sK1n7Wy14a"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u9xwRjuY5CDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "from skimage.io import imshow\n",
        "import math"
      ],
      "metadata": {
        "id": "v5Y0qMK7y17k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if row has any NaN values \n",
        "def has_nan(keypoints):\n",
        "      for i in range(len(keypoints)):\n",
        "          if math.isnan(keypoints[i]):\n",
        "              return True\n",
        "      return False"
      ],
      "metadata": {
        "id": "bsO89AWyy1_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function which plots an image with it's corresponding keypoints\n",
        "def visualize_points(img, points):\n",
        "      fig,ax = plt.subplots(1)\n",
        "      ax.set_aspect('equal')\n",
        "      imshow(img)\n",
        "      for i in range(0,len(points),2):\n",
        "          # Denormalize x-coordinate\n",
        "          x_renorm = (points[i]+0.5)*96\n",
        "          # Denormalize y-coordinate\n",
        "          y_renorm = (points[i+1]+0.5)*96\n",
        "          # Plot the keypoints at the x and y coordinates\n",
        "          circ = Circle((x_renorm, y_renorm),1, color='r')\n",
        "          ax.add_patch(circ)\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "YoX0Fmzc5X8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data as Dataframes\n",
        "training = pd.read_csv('data/training.csv')\n",
        "test = pd.read_csv('data/test.csv')"
      ],
      "metadata": {
        "id": "QtofyeJS5YBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training data\n",
        "imgs_train = []\n",
        "points_train = []\n",
        "for i in range(len(training)):\n",
        "    points = training.iloc[i,:-1]\n",
        "    if has_nan(points) is False:\n",
        "        # Get the image data\n",
        "        test_image = training.iloc[i,-1] \n",
        "        test_image = np.array(test_image.split(' ')).astype(int)\n",
        "        # Reshape into an array of size 96x96\n",
        "        test_image = np.reshape(test_image, (96,96))\n",
        "        # Normalize image\n",
        "        test_image = test_image/255\n",
        "        imgs_train.append(test_image)\n",
        "\n",
        "        keypoints = training.iloc[i,:-1].astype(int).values\n",
        "        # Normalize keypoint coordinates\n",
        "        keypoints = keypoints/96 - 0.5  \n",
        "        points_train.append(keypoints)\n",
        "\n",
        "imgs_train = np.array(imgs_train)    \n",
        "points_train = np.array(points_train)  "
      ],
      "metadata": {
        "id": "qdiBrLZ35YE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get test data\n",
        "imgs_test = []\n",
        "for i in range(len(test)):\n",
        "    # Get the image data\n",
        "    test_image = test.iloc[i,-1]\n",
        "    test_image = np.array(test_image.split(' ')).astype(int)\n",
        "    # Reshape into an array of size 96x96\n",
        "    test_image = np.reshape(test_image, (96,96))        \n",
        "    # Normalize image\n",
        "    test_image = test_image/255     \n",
        "    imgs_test.append(test_image)\n",
        "    \n",
        "imgs_test = np.array(imgs_test)"
      ],
      "metadata": {
        "id": "ApTcUfzx5YIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation by mirroring the images\n",
        "def augment(img, points):\n",
        "      # Mirror the image\n",
        "      f_img = img[:, ::-1]\n",
        "      # Mirror the key point coordinates\n",
        "      for i in range(0,len(points),2):\n",
        "          # Denormalize x-coordinate\n",
        "          x_renorm = (points[i]+0.5)*96\n",
        "          # Get distance to midpoint\n",
        "          x_renorm_flipped = x_renorm - 2*dx\n",
        "          # Normalize x-coordinate\n",
        "          points[i] = x_renorm_flipped/96 - 0.5\n",
        "      return f_img, points\n",
        "\n",
        "aug_imgs_train = []\n",
        "aug_points_train = []\n",
        "for i, img in enumerate(imgs_train):\n",
        "      f_img, f_points = augment(img, points_train[i])\n",
        "      aug_imgs_train.append(f_img)\n",
        "      aug_points_train.append(f_points)\n",
        "\n",
        "aug_imgs_train = np.array(aug_imgs_train)\n",
        "aug_points_train = np.array(aug_points_train)       "
      ],
      "metadata": {
        "id": "FRzsOXn15YLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the original data and augmented data\n",
        "imgs_total = np.concatenate((imgs_train, aug_imgs_train), axis=0)       \n",
        "points_total = np.concatenate((points_train, aug_points_train), axis=0)"
      ],
      "metadata": {
        "id": "O0MEYr8g5YPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_data():\n",
        "    imgs_total_reshaped = np.reshape(imgs_total, (imgs_total.shape[0],imgs_total.shape[1],imgs_total.shape[2], 1))\n",
        "    return imgs_total_reshaped,points_total"
      ],
      "metadata": {
        "id": "AHT8Qq2z5YS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_data():\n",
        "    return imgs_test"
      ],
      "metadata": {
        "id": "n3DfOlAG5YWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Implement the model in real-time"
      ],
      "metadata": {
        "id": "CdEBQ8Tp5YaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "from training import get_model, load_trained_model, compile_model\n",
        "import cv2"
      ],
      "metadata": {
        "id": "qovtvv315Yit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model = get_model()\n",
        "compile_model(model)\n",
        "load_trained_model(model)"
      ],
      "metadata": {
        "id": "XwPUKCZq5Yl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get frontal face haar cascade\n",
        "face_cascade = cv2.CascadeClassifier('cascades/haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "-XNy17DH5Ypf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get webcam\n",
        "camera = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "faz1tEY_5Ysl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the program infinitely\n",
        "while True:\n",
        "    # Read data from the webcam\n",
        "    grab_trueorfalse, img = camera.read()\n",
        "\n",
        "    # Preprocess input fram webcam & Convert RGB data to Grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Identify faces in the webcam        \n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    # For each detected face using tha Haar cascade\n",
        "    for (x,y,w,h) in faces:\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        img_copy = np.copy(img)\n",
        "        img_copy_1 = np.copy(img)\n",
        "        roi_color = img_copy_1[y:y+h, x:x+w]\n",
        "\n",
        "        # Width of region where face is detected\n",
        "        width_original = roi_gray.shape[1]\n",
        "        # Height of region where face is detected\n",
        "        height_original = roi_gray.shape[0]\n",
        "        # Resize image to size 96x96\n",
        "        img_gray = cv2.resize(roi_gray, (96, 96))\n",
        "        # Normalize the image data \n",
        "        img_gray = img_gray/255\n",
        "\n",
        "        # Model takes input of shape = [batch_size, height, width, no. of channels]\n",
        "        img_model = np.reshape(img_gray, (1,96,96,1))\n",
        "        # Predict keypoints for the current input\n",
        "        keypoints = model.predict(img_model)[0]\n",
        "\n",
        "        # Keypoints are saved as (x1, y1, x2, y2, ......)\n",
        "        # Read alternate elements starting from index 0\n",
        "        x_coords = keypoints[0::2]\n",
        "        # Read alternate elements starting from index 1\n",
        "        y_coords = keypoints[1::2]\n",
        "\n",
        "        # Denormalize x-coordinate\n",
        "        x_coords_denormalized = (x_coords+0.5)*width_original\n",
        "        # Denormalize y-coordinate\n",
        "        y_coords_denormalized = (y_coords+0.5)*height_original\n",
        "\n",
        "        # Plot the keypoints at the x and y coordinates\n",
        "        for i in range(len(x_coords)):\n",
        "             cv2.circle(roi_color, (x_coords_denormalized[i], y_coords_denormalized[i]), 2, (255,255,0), -1)\n",
        "\n",
        "        # Particular keypoints for scaling and positioning of the filter\n",
        "        left_lip_coords = (int(x_coords_denormalized[11]), int(y_coords_denormalized[11]))\n",
        "        right_lip_coords = (int(x_coords_denormalized[12]), int(y_coords_denormalized[12]))\n",
        "        top_lip_coords = (int(x_coords_denormalized[13]), int(y_coords_denormalized[13]))\n",
        "        bottom_lip_coords = (int(x_coords_denormalized[14]), int(y_coords_denormalized[14]))\n",
        "        left_eye_coords = (int(x_coords_denormalized[3]), int(y_coords_denormalized[3]))\n",
        "        right_eye_coords = (int(x_coords_denormalized[5]), int(y_coords_denormalized[5]))\n",
        "        brow_coords = (int(x_coords_denormalized[6]), int(y_coords_denormalized[6]))\n",
        "\n",
        "        # Scale filter according to keypoint coordinates\n",
        "        beard_width = right_lip_coords[0] - left_lip_coords[0]\n",
        "        glasses_width = right_eye_coords[0] - left_eye_coords[0]\n",
        "\n",
        "        # Used for transparency overlay of filter using the alpha channel\n",
        "        img_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2BGRA)\n",
        "\n",
        "        # Sunlasses filter\n",
        "        sunglasses = cv2.imread('filters/sunglasses.png', -1)\n",
        "        sunglasses = cv2.resize(sunglasses, (sunglasses_width*2,150))\n",
        "        sgw,sgh,sgc = sunglasses.shape\n",
        "        \n",
        "        # Overlay the filter based on the alpha channel\n",
        "        for i in range(0,sgw):       \n",
        "            for j in range(0,sgh):\n",
        "                if sunglasses[i,j][3] != 0:\n",
        "                    img_copy[brow_coords[1]+i+y-50, left_eye_coords[0]+j+x-60] = sunglasses[i,j]\n",
        "\n",
        "        # Rainbow filter\n",
        "        rainbow = cv2.imread('filters/rainbow.png', -1)\n",
        "        rainbow = cv2.resize(rainbow, (rainbow_width* _ ))\n",
        "        rbw,rbh, rbc = rainbow.shape\n",
        "\n",
        "        # Overlay the filter based on the alpha channel\n",
        "        for i in range(0,rbw):\n",
        "            for j in range(0,rbh):\n",
        "                 if rainbow[i,j][3] != 0:\n",
        "                       img_copy[brow_coords[1]+i+y-50, left_eye_coords[0]+j+x-60] = rainbow[i,j]\n",
        "\n",
        "        # Glasses filter\n",
        "        glasses = cv2.imread('filters/glasses.png', -1)\n",
        "        glasses = cv2.resize(sunglasses, (glasses_width*2,150))\n",
        "        gw,gh,gc = glasses.shape\n",
        "        \n",
        "        # Overlay the filter based on the alpha channel\n",
        "        for i in range(0,gw):       \n",
        "            for j in range(0,gh):\n",
        "                if glasses[i,j][3] != 0:\n",
        "                    img_copy[brow_coords[1]+i+y-50, left_eye_coords[0]+j+x-60] = glasses[i,j]\n",
        "\n",
        "        \n",
        "        # Demon mask filter\n",
        "        demon =  cv2.imread('filters/demon.png', -1)\n",
        "        demon = cv2.resize(demon, (demon_width*2,150))\n",
        "        dw,dh,dc = demon.shape\n",
        "        \n",
        "        # Overlay the filter based on the alpha channel\n",
        "        for i in range(0,dw):       \n",
        "            for j in range(0,dh):\n",
        "                if demon[i,j][3] != 0:\n",
        "                    img_copy[brow_coords[1]+i+y-50, left_eye_coords[0]+j+x-60] = demon[i,j]\n",
        "\n",
        "        \n",
        "        # Doc Dog filter\n",
        "        doc_dog =  cv2.imread('filters/doc_dog.png', -1)\n",
        "        doc_dog = cv2.resize(doc_dog, (doc_dog_width*2,150))\n",
        "        ddw,ddh,ddc = doc_dog.shape\n",
        "        \n",
        "        # Overlay the filter based on the alpha channel\n",
        "        for i in range(0,ddw):       \n",
        "            for j in range(0,ddh):\n",
        "                if doc_dog[i,j][3] != 0:\n",
        "                    img_copy[brow_coords[1]+i+y-50, left_eye_coords[0]+j+x-60] = doc_dog[i,j]\n",
        "\n",
        "\n",
        "        # King Wig filter\n",
        "        king_wig =  cv2.imread('filters/king_wig.png', -1)\n",
        "        king_wig = cv2.resize(king_wig, (king_wig_width*2,150))\n",
        "        kww,kwh,kwc = king_wig.shape\n",
        "        \n",
        "        # Overlay the filter based on the alpha channel\n",
        "        for i in range(0,kww):       \n",
        "            for j in range(0,kwh):\n",
        "                if king_wig[i,j][3] != 0:\n",
        "                    img_copy[brow_coords[1]+i+y-50, left_eye_coords[0]+j+x-60] = king_wig[i,j]\n",
        "\n",
        "\n",
        "        # Top Hat filter\n",
        "        top_hat =  cv2.imread('filters/top_hat.png', -1)\n",
        "        top_hat = cv2.resize(top_hat, (top_hat_width*2,150))\n",
        "        thw,thh,thc = top_hat.shape\n",
        "        \n",
        "        # Overlay the filter based on the alpha channel\n",
        "        for i in range(0,thw):       \n",
        "            for j in range(0,thh):\n",
        "                if top_hat[i,j][3] != 0:\n",
        "                    img_copy[brow_coords[1]+i+y-50, left_eye_coords[0]+j+x-60] = top_hat[i,j]\n",
        "\n",
        "        # Dalmatian filter\n",
        "        dalmatian =  cv2.imread('filters/dalmatian.png', -1)\n",
        "        dalmatian = cv2.resize(dalmatian, (dalmatian_width*2,150))\n",
        "        daw,dah,dac = dalmatian.shape\n",
        "        \n",
        "        # Overlay the filter based on the alpha channel\n",
        "        for i in range(0,daw):       \n",
        "            for j in range(0,dah):\n",
        "                if dalmatian[i,j][3] != 0:\n",
        "                    img_copy[brow_coords[1]+i+y-50, left_eye_coords[0]+j+x-60] = dalmatian[i,j]\n",
        "\n",
        "\n",
        "         # Revert back to background\n",
        "         img_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "         # Output with the filter placed on the face\n",
        "         cv2.imshow('Output',img_copy)\n",
        "\n",
        "         # Place keypoints on the webcam input\n",
        "         cv2.imshow('Keypoints predicted',img_copy_1)\n",
        "\n",
        "      # Original webcame Input\n",
        "      cv2.imshow('Webcam',img)\n",
        "\n",
        "      # If 'f' is pressed, stop reading and break the loop\n",
        "      if cv2.waitKey(1) & 0xFF == ord(\"f\"):\n",
        "          break\n"
      ],
      "metadata": {
        "id": "0oONiq9W8TyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d_B2MpVq8T2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pMMiOq008T50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nec64PDL8T9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q0NaE4jy8UBJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}